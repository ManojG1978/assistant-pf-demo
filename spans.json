{
    "name": "run_conversation",
    "context": {
        "trace_id": "0x2003e6451fd0a4f57180c96bfb737ca2",
        "span_id": "0x2f9dd2e63a685f3d",
        "trace_state": "[]"
    },
    "kind": "SpanKind.INTERNAL",
    "parent_id": "0x274dd096714e8259",
    "start_time": "2024-04-30T20:40:30.366638Z",
    "end_time": "2024-04-30T20:40:30.377180Z",
    "status": {
        "status_code": "OK"
    },
    "attributes": {
        "framework": "promptflow",
        "span_type": "Function",
        "function": "run_conversation",
        "inputs": "{\n  \"chat_history\": [],\n  \"question\": \"test\"\n}",
        "output": "\"<async_generator object QueuedAsyncIteratorStream.aiter at 0x13802bc60>\""
    },
    "events": [
        {
            "name": "promptflow.function.inputs",
            "timestamp": "2024-04-30T20:40:30.366795Z",
            "attributes": {
                "payload": "{\n  \"chat_history\": [],\n  \"question\": \"test\"\n}"
            }
        },
        {
            "name": "promptflow.function.output",
            "timestamp": "2024-04-30T20:40:30.377129Z",
            "attributes": {
                "payload": "\"<async_generator object QueuedAsyncIteratorStream.aiter at 0x13802bc60>\""
            }
        }
    ],
    "links": [],
    "resource": {
        "attributes": {
            "service.name": "promptflow",
            "collection": "assistant-pf-demo"
        },
        "schema_url": ""
    }
}
{
    "name": "call_promptflow",
    "context": {
        "trace_id": "0x2003e6451fd0a4f57180c96bfb737ca2",
        "span_id": "0x274dd096714e8259",
        "trace_state": "[]"
    },
    "kind": "SpanKind.INTERNAL",
    "parent_id": null,
    "start_time": "2024-04-30T20:40:29.407840Z",
    "end_time": "2024-04-30T20:40:30.719453Z",
    "status": {
        "status_code": "UNSET"
    },
    "attributes": {
        "inputs": "{\"question\": \"test\"}",
        "span_type": "function",
        "framework": "promptflow",
        "function": "call_promptflow",
        "output": "Object of type async_generator is not JSON serializable"
    },
    "events": [],
    "links": [],
    "resource": {
        "attributes": {
            "service.name": "promptflow",
            "collection": "assistant-pf-demo"
        },
        "schema_url": ""
    }
}
{
    "name": "openai_chat_async",
    "context": {
        "trace_id": "0x2003e6451fd0a4f57180c96bfb737ca2",
        "span_id": "0x069795b63654ddfc",
        "trace_state": "[]"
    },
    "kind": "SpanKind.INTERNAL",
    "parent_id": "0x8fc272a9f8494244",
    "start_time": "2024-04-30T20:40:30.790768Z",
    "end_time": "2024-04-30T20:40:31.943844Z",
    "status": {
        "status_code": "OK"
    },
    "attributes": {
        "framework": "promptflow",
        "span_type": "LLM",
        "function": "openai.resources.chat.completions.AsyncCompletions.create",
        "inputs": "{\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"\\n                You are a helpful assistant that helps the user potentially with the help of some functions.\\n\\n                If you are using multiple tools to solve a user's task, make sure to communicate \\n                information learned from one tool to the next tool.\\n                First, make a plan of how you will use the tools to solve the user's task and communicated\\n                that plan to the user with the first response. Then execute the plan making sure to communicate\\n                the required information between tools since tools only see the information passed to them;\\n                They do not have access to the chat history.\\n                If you think that tool use can be parallelized (e.g. to get weather data for multiple cities) \\n                make sure to use the multi_tool_use.parallel function to execute.\\n\\n                Only use a tool when it is necessary to solve the user's task. \\n                Don't use a tool if you can answer the user's question directly.\\n                Only use the tools provided in the tools list -- don't make up tools!!\\n\\n                Anything that would benefit from a tabular presentation should be returned as markup table.\\n                 \"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"test\"\n    }\n  ],\n  \"model\": \"gpt-35-turbo-1106\",\n  \"tools\": [\n    {\n      \"type\": \"function\",\n      \"function\": {\n        \"name\": \"sales_data_insights\",\n        \"description\": \"\\n            get some data insights about the contoso sales data. This tool has information about total sales, return return rates, discounts given, etc., by date, product category, etc.\\n            you can ask questions like:\\n            - query for the month with the strongest revenue\\n            - which day of the week has the least sales in january\\n            - query the average value of orders by month\\n            - what is the average sale value for Tuesdays\\n            If you are unsure of the data available, you can ask for a list of categories, days, etc.\\n            - query for all the values for the main_category\\n            If a query cannot be answered, the tool will return a message saying that the query is not supported. otherwise the data will be returned.\\n            \",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"question\": {\n              \"type\": \"string\",\n              \"description\": \"The question you want to ask the tool in plain English. e.g. 'what is the average sale value for Tuesdays'\"\n            }\n          },\n          \"required\": [\n            \"question\"\n          ]\n        }\n      }\n    }\n  ],\n  \"tool_choice\": \"auto\"\n}",
        "llm.response.model": "gpt-35-turbo",
        "llm.generated_message": "{\n  \"content\": \"It looks like you are testing the functionality. How can I assist you today?\",\n  \"role\": \"assistant\",\n  \"function_call\": null,\n  \"tool_calls\": null\n}",
        "__computed__.cumulative_token_count.completion": 17,
        "__computed__.cumulative_token_count.prompt": 450,
        "__computed__.cumulative_token_count.total": 467,
        "llm.usage.completion_tokens": 17,
        "llm.usage.prompt_tokens": 450,
        "llm.usage.total_tokens": 467,
        "output": "{\n  \"id\": \"chatcmpl-9JoZAmya2Ls1dikNdVzwcgbi46ZJs\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": \"It looks like you are testing the functionality. How can I assist you today?\",\n        \"role\": \"assistant\",\n        \"function_call\": null,\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1714509636,\n  \"model\": \"gpt-35-turbo\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": \"fp_2f57f81c11\",\n  \"usage\": {\n    \"completion_tokens\": 17,\n    \"prompt_tokens\": 450,\n    \"total_tokens\": 467\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}"
    },
    "events": [
        {
            "name": "promptflow.function.inputs",
            "timestamp": "2024-04-30T20:40:30.791747Z",
            "attributes": {
                "payload": "{\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"\\n                You are a helpful assistant that helps the user potentially with the help of some functions.\\n\\n                If you are using multiple tools to solve a user's task, make sure to communicate \\n                information learned from one tool to the next tool.\\n                First, make a plan of how you will use the tools to solve the user's task and communicated\\n                that plan to the user with the first response. Then execute the plan making sure to communicate\\n                the required information between tools since tools only see the information passed to them;\\n                They do not have access to the chat history.\\n                If you think that tool use can be parallelized (e.g. to get weather data for multiple cities) \\n                make sure to use the multi_tool_use.parallel function to execute.\\n\\n                Only use a tool when it is necessary to solve the user's task. \\n                Don't use a tool if you can answer the user's question directly.\\n                Only use the tools provided in the tools list -- don't make up tools!!\\n\\n                Anything that would benefit from a tabular presentation should be returned as markup table.\\n                 \"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"test\"\n    }\n  ],\n  \"model\": \"gpt-35-turbo-1106\",\n  \"tools\": [\n    {\n      \"type\": \"function\",\n      \"function\": {\n        \"name\": \"sales_data_insights\",\n        \"description\": \"\\n            get some data insights about the contoso sales data. This tool has information about total sales, return return rates, discounts given, etc., by date, product category, etc.\\n            you can ask questions like:\\n            - query for the month with the strongest revenue\\n            - which day of the week has the least sales in january\\n            - query the average value of orders by month\\n            - what is the average sale value for Tuesdays\\n            If you are unsure of the data available, you can ask for a list of categories, days, etc.\\n            - query for all the values for the main_category\\n            If a query cannot be answered, the tool will return a message saying that the query is not supported. otherwise the data will be returned.\\n            \",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"question\": {\n              \"type\": \"string\",\n              \"description\": \"The question you want to ask the tool in plain English. e.g. 'what is the average sale value for Tuesdays'\"\n            }\n          },\n          \"required\": [\n            \"question\"\n          ]\n        }\n      }\n    }\n  ],\n  \"tool_choice\": \"auto\"\n}"
            }
        },
        {
            "name": "promptflow.llm.generated_message",
            "timestamp": "2024-04-30T20:40:31.938429Z",
            "attributes": {
                "payload": "{\n  \"content\": \"It looks like you are testing the functionality. How can I assist you today?\",\n  \"role\": \"assistant\",\n  \"function_call\": null,\n  \"tool_calls\": null\n}"
            }
        },
        {
            "name": "promptflow.function.output",
            "timestamp": "2024-04-30T20:40:31.943655Z",
            "attributes": {
                "payload": "{\n  \"id\": \"chatcmpl-9JoZAmya2Ls1dikNdVzwcgbi46ZJs\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": \"It looks like you are testing the functionality. How can I assist you today?\",\n        \"role\": \"assistant\",\n        \"function_call\": null,\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1714509636,\n  \"model\": \"gpt-35-turbo\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": \"fp_2f57f81c11\",\n  \"usage\": {\n    \"completion_tokens\": 17,\n    \"prompt_tokens\": 450,\n    \"total_tokens\": 467\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}"
            }
        }
    ],
    "links": [],
    "resource": {
        "attributes": {
            "service.name": "promptflow",
            "collection": "assistant-pf-demo"
        },
        "schema_url": ""
    }
}
{
    "name": "call_llm",
    "context": {
        "trace_id": "0x2003e6451fd0a4f57180c96bfb737ca2",
        "span_id": "0x8fc272a9f8494244",
        "trace_state": "[]"
    },
    "kind": "SpanKind.INTERNAL",
    "parent_id": "0x2f9dd2e63a685f3d",
    "start_time": "2024-04-30T20:40:30.790086Z",
    "end_time": "2024-04-30T20:40:32.007717Z",
    "status": {
        "status_code": "OK"
    },
    "attributes": {
        "framework": "promptflow",
        "span_type": "Function",
        "function": "call_llm",
        "inputs": "{\n  \"message_history\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"\\n                You are a helpful assistant that helps the user potentially with the help of some functions.\\n\\n                If you are using multiple tools to solve a user's task, make sure to communicate \\n                information learned from one tool to the next tool.\\n                First, make a plan of how you will use the tools to solve the user's task and communicated\\n                that plan to the user with the first response. Then execute the plan making sure to communicate\\n                the required information between tools since tools only see the information passed to them;\\n                They do not have access to the chat history.\\n                If you think that tool use can be parallelized (e.g. to get weather data for multiple cities) \\n                make sure to use the multi_tool_use.parallel function to execute.\\n\\n                Only use a tool when it is necessary to solve the user's task. \\n                Don't use a tool if you can answer the user's question directly.\\n                Only use the tools provided in the tools list -- don't make up tools!!\\n\\n                Anything that would benefit from a tabular presentation should be returned as markup table.\\n                 \"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"test\"\n    }\n  ],\n  \"stream\": \"<data_analyst.functions_flow.QueuedAsyncIteratorStream object at 0x13882c810>\"\n}",
        "__computed__.cumulative_token_count.completion": 17,
        "__computed__.cumulative_token_count.prompt": 450,
        "__computed__.cumulative_token_count.total": 467,
        "output": "[\n  {\n    \"role\": \"system\",\n    \"content\": \"\\n                You are a helpful assistant that helps the user potentially with the help of some functions.\\n\\n                If you are using multiple tools to solve a user's task, make sure to communicate \\n                information learned from one tool to the next tool.\\n                First, make a plan of how you will use the tools to solve the user's task and communicated\\n                that plan to the user with the first response. Then execute the plan making sure to communicate\\n                the required information between tools since tools only see the information passed to them;\\n                They do not have access to the chat history.\\n                If you think that tool use can be parallelized (e.g. to get weather data for multiple cities) \\n                make sure to use the multi_tool_use.parallel function to execute.\\n\\n                Only use a tool when it is necessary to solve the user's task. \\n                Don't use a tool if you can answer the user's question directly.\\n                Only use the tools provided in the tools list -- don't make up tools!!\\n\\n                Anything that would benefit from a tabular presentation should be returned as markup table.\\n                 \"\n  },\n  {\n    \"role\": \"user\",\n    \"content\": \"test\"\n  },\n  {\n    \"content\": \"It looks like you are testing the functionality. How can I assist you today?\",\n    \"role\": \"assistant\",\n    \"function_call\": null,\n    \"tool_calls\": null\n  }\n]"
    },
    "events": [
        {
            "name": "promptflow.function.inputs",
            "timestamp": "2024-04-30T20:40:30.790429Z",
            "attributes": {
                "payload": "{\n  \"message_history\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"\\n                You are a helpful assistant that helps the user potentially with the help of some functions.\\n\\n                If you are using multiple tools to solve a user's task, make sure to communicate \\n                information learned from one tool to the next tool.\\n                First, make a plan of how you will use the tools to solve the user's task and communicated\\n                that plan to the user with the first response. Then execute the plan making sure to communicate\\n                the required information between tools since tools only see the information passed to them;\\n                They do not have access to the chat history.\\n                If you think that tool use can be parallelized (e.g. to get weather data for multiple cities) \\n                make sure to use the multi_tool_use.parallel function to execute.\\n\\n                Only use a tool when it is necessary to solve the user's task. \\n                Don't use a tool if you can answer the user's question directly.\\n                Only use the tools provided in the tools list -- don't make up tools!!\\n\\n                Anything that would benefit from a tabular presentation should be returned as markup table.\\n                 \"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"test\"\n    }\n  ],\n  \"stream\": \"<data_analyst.functions_flow.QueuedAsyncIteratorStream object at 0x13882c810>\"\n}"
            }
        },
        {
            "name": "promptflow.function.output",
            "timestamp": "2024-04-30T20:40:32.007670Z",
            "attributes": {
                "payload": "[\n  {\n    \"role\": \"system\",\n    \"content\": \"\\n                You are a helpful assistant that helps the user potentially with the help of some functions.\\n\\n                If you are using multiple tools to solve a user's task, make sure to communicate \\n                information learned from one tool to the next tool.\\n                First, make a plan of how you will use the tools to solve the user's task and communicated\\n                that plan to the user with the first response. Then execute the plan making sure to communicate\\n                the required information between tools since tools only see the information passed to them;\\n                They do not have access to the chat history.\\n                If you think that tool use can be parallelized (e.g. to get weather data for multiple cities) \\n                make sure to use the multi_tool_use.parallel function to execute.\\n\\n                Only use a tool when it is necessary to solve the user's task. \\n                Don't use a tool if you can answer the user's question directly.\\n                Only use the tools provided in the tools list -- don't make up tools!!\\n\\n                Anything that would benefit from a tabular presentation should be returned as markup table.\\n                 \"\n  },\n  {\n    \"role\": \"user\",\n    \"content\": \"test\"\n  },\n  {\n    \"content\": \"It looks like you are testing the functionality. How can I assist you today?\",\n    \"role\": \"assistant\",\n    \"function_call\": null,\n    \"tool_calls\": null\n  }\n]"
            }
        }
    ],
    "links": [],
    "resource": {
        "attributes": {
            "service.name": "promptflow",
            "collection": "assistant-pf-demo"
        },
        "schema_url": ""
    }
}
{
    "name": "stream",
    "context": {
        "trace_id": "0x2003e6451fd0a4f57180c96bfb737ca2",
        "span_id": "0xe8413425c15d9170",
        "trace_state": "[]"
    },
    "kind": "SpanKind.INTERNAL",
    "parent_id": "0x2f9dd2e63a685f3d",
    "start_time": "2024-04-30T20:40:32.067870Z",
    "end_time": "2024-04-30T20:40:32.067923Z",
    "status": {
        "status_code": "UNSET"
    },
    "attributes": {
        "output": "[\"It looks like you are testing the functionality. How can I assist you today?\\n\\n---\\n\"]"
    },
    "events": [],
    "links": [],
    "resource": {
        "attributes": {
            "service.name": "promptflow",
            "collection": "assistant-pf-demo"
        },
        "schema_url": ""
    }
}
{
    "name": "Iterated(run_conversation)",
    "context": {
        "trace_id": "0xa50e2050b8336a9a5fb0106c1b01509d",
        "span_id": "0x20c8e26f3aacd5f1",
        "trace_state": "[]"
    },
    "kind": "SpanKind.INTERNAL",
    "parent_id": null,
    "start_time": "2024-04-30T20:40:30.789242Z",
    "end_time": "2024-04-30T20:40:32.132534Z",
    "status": {
        "status_code": "OK"
    },
    "attributes": {
        "framework": "promptflow",
        "span_type": "Function",
        "function": "run_conversation",
        "inputs": "{\n  \"chat_history\": [],\n  \"question\": \"test\"\n}",
        "output": "\"[\\n  \\\"It looks like you are testing the functionality. How can I assist you today?\\\\n\\\\n---\\\\n\\\"\\n]\""
    },
    "events": [
        {
            "name": "promptflow.function.inputs",
            "timestamp": "2024-04-30T20:40:30.789393Z",
            "attributes": {
                "payload": "{\n  \"chat_history\": [],\n  \"question\": \"test\"\n}"
            }
        },
        {
            "name": "promptflow.function.output",
            "timestamp": "2024-04-30T20:40:32.132496Z",
            "attributes": {
                "payload": "\"[\\n  \\\"It looks like you are testing the functionality. How can I assist you today?\\\\n\\\\n---\\\\n\\\"\\n]\""
            }
        }
    ],
    "links": [
        {
            "context": {
                "trace_id": "0x2003e6451fd0a4f57180c96bfb737ca2",
                "span_id": "0x2f9dd2e63a685f3d",
                "trace_state": "[]"
            },
            "attributes": {}
        }
    ],
    "resource": {
        "attributes": {
            "service.name": "promptflow",
            "collection": "assistant-pf-demo"
        },
        "schema_url": ""
    }
}
